{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data-scientist-exercise01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primary References:\n",
    "- https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "- http://queirozf.com/entries/one-hot-encoding-a-feature-on-a-pandas-dataframe-an-example\n",
    "- https://www.geeksforgeeks.org/how-to-get-column-names-in-pandas-dataframe/\n",
    "- https://www.geeksforgeeks.org/confusion-matrix-machine-learning/ \n",
    "- StackOverflow\n",
    "- StackExchange\n",
    "- ect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Import the \"flattened\" table (or CSV file) into your open source analytic environment of choice (R, Python, Java, etc.) and stage it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.7/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydotplus in /srv/conda/envs/notebook/lib/python3.7/site-packages (2.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in /srv/conda/envs/notebook/lib/python3.7/site-packages (from pydotplus) (2.4.0)\n",
      "Requirement already satisfied: graphviz in /srv/conda/envs/notebook/lib/python3.7/site-packages (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import classification_report \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import sys\n",
    "!{sys.executable} -m pip install pydotplus\n",
    "import sys\n",
    "!{sys.executable} -m pip install graphviz\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'workClass', 'eduLevel', 'eduNum', 'maritalStatus',\n",
       "       'occupation', 'relationship', 'race', 'sex', 'capitalGain',\n",
       "       'capitalLoss', 'hoursPerWeek', 'country', 'over50K'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydata= \"flattenedRecords.csv\"\n",
    "df = pd.read_csv(mydata) \n",
    "df.head()\n",
    "df.columns\n",
    "#df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Split the data into training, validation, and test data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    76.071823\n",
       "1    23.928177\n",
       "Name: over50K, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the current # of 0 and 1 in column\n",
    "(df['over50K'].value_counts()/df['over50K'].count())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "age\n",
      "eduNum\n",
      "capitalGain\n",
      "capitalLoss\n",
      "hoursPerWeek\n",
      "over50K\n",
      "workClass_Federal-gov\n",
      "workClass_Local-gov\n",
      "workClass_Never-worked\n",
      "workClass_Private\n",
      "workClass_Self-emp-inc\n",
      "workClass_Self-emp-not-inc\n",
      "workClass_State-gov\n",
      "workClass_Without-pay\n",
      "eduLevel_10th\n",
      "eduLevel_11th\n",
      "eduLevel_12th\n",
      "eduLevel_1st-4th\n",
      "eduLevel_5th-6th\n",
      "eduLevel_7th-8th\n",
      "eduLevel_9th\n",
      "eduLevel_Assoc-acdm\n",
      "eduLevel_Assoc-voc\n",
      "eduLevel_Bachelors\n",
      "eduLevel_Doctorate\n",
      "eduLevel_HS-grad\n",
      "eduLevel_Masters\n",
      "eduLevel_Preschool\n",
      "eduLevel_Prof-school\n",
      "eduLevel_Some-college\n",
      "maritalStatus_Divorced\n",
      "maritalStatus_Married-AF-spouse\n",
      "maritalStatus_Married-civ-spouse\n",
      "maritalStatus_Married-spouse-absent\n",
      "maritalStatus_Never-married\n",
      "maritalStatus_Separated\n",
      "maritalStatus_Widowed\n",
      "occupation_Adm-clerical\n",
      "occupation_Armed-Forces\n",
      "occupation_Craft-repair\n",
      "occupation_Exec-managerial\n",
      "occupation_Farming-fishing\n",
      "occupation_Handlers-cleaners\n",
      "occupation_Machine-op-inspct\n",
      "occupation_Other-service\n",
      "occupation_Priv-house-serv\n",
      "occupation_Prof-specialty\n",
      "occupation_Protective-serv\n",
      "occupation_Sales\n",
      "occupation_Tech-support\n",
      "occupation_Transport-moving\n",
      "relationship_Husband\n",
      "relationship_Not-in-family\n",
      "relationship_Other-relative\n",
      "relationship_Own-child\n",
      "relationship_Unmarried\n",
      "relationship_Wife\n",
      "race_Amer-Indian-Eskimo\n",
      "race_Asian-Pac-Islander\n",
      "race_Black\n",
      "race_Other\n",
      "race_White\n",
      "sex_Female\n",
      "sex_Male\n",
      "country_Cambodia\n",
      "country_Canada\n",
      "country_China\n",
      "country_Columbia\n",
      "country_Cuba\n",
      "country_Dominican-Republic\n",
      "country_Ecuador\n",
      "country_El-Salvador\n",
      "country_England\n",
      "country_France\n",
      "country_Germany\n",
      "country_Greece\n",
      "country_Guatemala\n",
      "country_Haiti\n",
      "country_Holand-Netherlands\n",
      "country_Honduras\n",
      "country_Hong\n",
      "country_Hungary\n",
      "country_India\n",
      "country_Iran\n",
      "country_Ireland\n",
      "country_Italy\n",
      "country_Jamaica\n",
      "country_Japan\n",
      "country_Laos\n",
      "country_Mexico\n",
      "country_Nicaragua\n",
      "country_Outlying-US(Guam-USVI-etc)\n",
      "country_Peru\n",
      "country_Philippines\n",
      "country_Poland\n",
      "country_Portugal\n",
      "country_Puerto-Rico\n",
      "country_Scotland\n",
      "country_South\n",
      "country_Taiwan\n",
      "country_Thailand\n",
      "country_Trinadad&Tobago\n",
      "country_United-States\n",
      "country_Vietnam\n",
      "country_Yugoslavia\n"
     ]
    }
   ],
   "source": [
    "# converting all '?' to NaN\n",
    "df = df.mask(df=='?', float('NaN'))\n",
    "\n",
    "#SKLearn only takes # so I have to change all of the Strings to #\n",
    "# use pd.concat to join the new columns with your original dataframe\n",
    "df = pd.concat([df,pd.get_dummies(df['workClass'], prefix='workClass')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['eduLevel'], prefix='eduLevel')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['maritalStatus'], prefix='maritalStatus')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['occupation'], prefix='occupation')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['relationship'], prefix='relationship')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['race'], prefix='race')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['sex'], prefix='sex')],axis=1)\n",
    "df = pd.concat([df,pd.get_dummies(df['country'], prefix='country')],axis=1)\n",
    "                     \n",
    "# get rid of the original column\n",
    "df.drop(['workClass'],axis=1, inplace=True)\n",
    "df.drop(['eduLevel'],axis=1, inplace=True)\n",
    "df.drop(['maritalStatus'],axis=1, inplace=True)\n",
    "df.drop(['occupation'],axis=1, inplace=True)\n",
    "df.drop(['relationship'],axis=1, inplace=True)\n",
    "df.drop(['race'],axis=1, inplace=True)\n",
    "df.drop(['sex'],axis=1, inplace=True)\n",
    "df.drop(['country'],axis=1, inplace=True)\n",
    "\n",
    "#show all column names\n",
    "for col in df.columns: \n",
    "    print(col) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape of XTrain: (31258, 105)\n",
      "y_train Shape of YTrain: (31258, 1)\n",
      "X_test Shape of XTest: (9769, 105)\n",
      "y_test Shape of YTest: (9769, 1)\n",
      "Shape of XValidation: (7815, 105)\n",
      "Shape of YValidation: (7815, 1)\n"
     ]
    }
   ],
   "source": [
    "#split dataset in target and other\n",
    "target = ['over50K']\n",
    "\n",
    "other = ['id', 'age', 'eduNum', 'capitalGain', 'capitalLoss', 'hoursPerWeek',\n",
    "         'workClass_Federal-gov', 'workClass_Local-gov',\n",
    "       'workClass_Never-worked', 'workClass_Private', 'workClass_Self-emp-inc',\n",
    "       'workClass_Self-emp-not-inc', 'workClass_State-gov',\n",
    "       'workClass_Without-pay', 'eduLevel_10th', 'eduLevel_11th',\n",
    "       'eduLevel_12th', 'eduLevel_1st-4th', 'eduLevel_5th-6th',\n",
    "       'eduLevel_7th-8th', 'eduLevel_9th', 'eduLevel_Assoc-acdm',\n",
    "       'eduLevel_Assoc-voc', 'eduLevel_Bachelors', 'eduLevel_Doctorate',\n",
    "       'eduLevel_HS-grad', 'eduLevel_Masters', 'eduLevel_Preschool',\n",
    "       'eduLevel_Prof-school', 'eduLevel_Some-college',\n",
    "       'maritalStatus_Divorced', 'maritalStatus_Married-AF-spouse',\n",
    "       'maritalStatus_Married-civ-spouse',\n",
    "       'maritalStatus_Married-spouse-absent', 'maritalStatus_Never-married',\n",
    "       'maritalStatus_Separated', 'maritalStatus_Widowed',\n",
    "       'occupation_Adm-clerical', 'occupation_Armed-Forces',\n",
    "       'occupation_Craft-repair', 'occupation_Exec-managerial',\n",
    "       'occupation_Farming-fishing', 'occupation_Handlers-cleaners',\n",
    "       'occupation_Machine-op-inspct', 'occupation_Other-service',\n",
    "       'occupation_Priv-house-serv', 'occupation_Prof-specialty',\n",
    "       'occupation_Protective-serv', 'occupation_Sales',\n",
    "       'occupation_Tech-support', 'occupation_Transport-moving',\n",
    "       'relationship_Husband', 'relationship_Not-in-family',\n",
    "       'relationship_Other-relative', 'relationship_Own-child',\n",
    "       'relationship_Unmarried', 'relationship_Wife',\n",
    "       'race_Amer-Indian-Eskimo', 'race_Asian-Pac-Islander', 'race_Black',\n",
    "       'race_Other', 'race_White', 'sex_Female', 'sex_Male','country_Cambodia', 'country_Canada','country_China',\n",
    "         'country_Columbia','country_Cuba','country_Dominican-Republic','country_Ecuador','country_El-Salvador',\n",
    "         'country_England','country_France','country_Germany','country_Greece','country_Guatemala','country_Haiti',\n",
    "         'country_Holand-Netherlands','country_Honduras','country_Hong','country_Hungary','country_India','country_Iran',\n",
    "         'country_Ireland','country_Italy','country_Jamaica','country_Japan','country_Laos','country_Mexico','country_Nicaragua',\n",
    "         'country_Outlying-US(Guam-USVI-etc)','country_Peru','country_Philippines','country_Poland','country_Portugal','country_Puerto-Rico', 'country_Scotland',\n",
    "       'country_South', 'country_Taiwan', 'country_Thailand',\n",
    "       'country_Trinadad&Tobago', 'country_United-States', 'country_Vietnam',\n",
    "       'country_Yugoslavia']\n",
    "\n",
    "X = df[other]\n",
    "y = df[target] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1) # 50% training and 20% test\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size = 0.2, random_state=2)# 50% training and 20% Validation\n",
    "\n",
    "#CHECK We expect the training features number of columns to match the testing feature number of columns and the number of rows to match for the respective training and testing features and the labels\n",
    "print('X_train Shape of XTrain:', X_train.shape)\n",
    "print('y_train Shape of YTrain:', y_train.shape)\n",
    "print('X_test Shape of XTest:', X_test.shape)\n",
    "print('y_test Shape of YTest:', y_test.shape)\n",
    "print('Shape of XValidation:', X_validation.shape)\n",
    "print('Shape of YValidation:', y_validation.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Develop a model that predicts whether individuals, based on the census variables provided, make over $50,000/year. Use over_50k as the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[6421 1009]\n",
      " [ 860 1479]] \n",
      "\n",
      "Accuracy: 0.8086805200122837 \n",
      "\n",
      "Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87      7430\n",
      "           1       0.59      0.63      0.61      2339\n",
      "\n",
      "    accuracy                           0.81      9769\n",
      "   macro avg       0.74      0.75      0.74      9769\n",
      "weighted avg       0.81      0.81      0.81      9769\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#ValueError: could not convert string to float: '?' \n",
    "    #for this reason I will now convert\n",
    "    \n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results,\"\\n\") \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred),\"\\n\")\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETTER Decision Tree classifer object\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=12)\n",
    "\n",
    "# Train Decision Tree Classifer\n",
    "clf = clf.fit(X_train,y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results,\"\\n\") \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred),\"\\n\")\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(dict(zip(X_test.columns, clf.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, importance in zip(df[other], clf.feature_importances_):\n",
    "    print(name, \"=\", importance)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [other[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(X_train,y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "results = confusion_matrix(y_test, y_pred) \n",
    "print('Confusion Matrix :')\n",
    "print(results,\"\\n\") \n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred),\"\\n\")\n",
    "print('Report : ')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, importance in zip(df[other], clf.feature_importances_):\n",
    "    print(name, \"=\", importance)\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [other[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\n",
    "fit = bestfeatures.fit(X_train,y_train)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "print(model.feature_importances_) #use inbuilt class feature_importances of tree based classifiers\n",
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
